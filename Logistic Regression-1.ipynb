{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6ad269-57db-41ac-87aa-5d2239a2dab4",
   "metadata": {},
   "source": [
    "# Logistic Regression-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75284a61-a017-40b5-8a5d-ee5bd400576e",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00061a49-7ef3-4457-9afc-c0190a86beeb",
   "metadata": {},
   "source": [
    "Linear Regression:- is a machine learning algorithm based on supervised regression algorithm. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting.\n",
    "\n",
    "Logistic regression:- is basically a supervised classification algorithm. In a classification problem, the target variable(or output), y, can take only discrete values for a given set of features(or inputs), X.\n",
    "\n",
    "1.\n",
    "\n",
    "Linear Regression:=Linear Regression is a supervised regression model.\n",
    "\n",
    "Logistic Regression is a supervised classification model.\n",
    "\n",
    "2.\n",
    "\n",
    "Equation of linear regression:y = a0 + a1x1 + a2x2 + … + aixiHere,\n",
    "y = response variable\n",
    "xi = ith predictor variable\n",
    "ai = average effect on y as xi increases by 1\t\n",
    "\n",
    "Equation of logistic regression=y(x) = e(a0 + a1x1 + a2x2 + … + aixi) / (1 + e(a0 + a1x1 + a2x2 + … + aixi))Here,\n",
    "y = response variable\n",
    "xi = ith predictor variable\n",
    "ai = average effect on y as xi increases by 1\n",
    "\n",
    "3.\n",
    "\n",
    "In Linear Regression, we predict the value by an integer number.\n",
    "\n",
    "In Logistic Regression, we predict the value by 1 or 0.\n",
    "\n",
    "4.\n",
    "\n",
    "Linear Regression:=Here no activation function is used.\n",
    "\n",
    "Logistic Regression:=Here activation function is used to convert a linear regression equation to the logistic regression equation\n",
    "\n",
    "5.\n",
    "\n",
    "Linear Regression:=Here no threshold value is needed.\n",
    "\n",
    "Logistic Regression:=Here a threshold value is added.\n",
    "\n",
    "6.\n",
    "\n",
    "Linear Regression:=Here we calculate Root Mean Square Error(RMSE) to predict the next weight value.\n",
    "\n",
    "Logistic Regression:=Here we use precision to predict the next weight value.\n",
    "\n",
    "7.\n",
    "\n",
    "Linear Regression:=Here dependent variable should be numeric and the response variable is continuous to value.\tHere the dependent variable consists of only two categories. \n",
    "\n",
    "Logistic Regression:=Logistic regression estimates the odds outcome of the dependent variable given a set of quantitative or categorical independent variables.\n",
    "\n",
    "8.\t\n",
    "\n",
    "Linear Regression:=It is based on the least square estimation.\n",
    "\n",
    "Logistic Regression:=It is based on maximum likelihood estimation.\n",
    "\n",
    "9.\n",
    "\n",
    "Linear Regression:=Here when we plot the training datasets, a straight line can be drawn that touches maximum plots.\n",
    "\n",
    "Logistic Regression:=Any change in the coefficient leads to a change in both the direction and the steepness of the logistic function. It means positive slopes result in an S-shaped curve and negative slopes result in a Z-shaped curve.\n",
    "\n",
    "10.\n",
    "\n",
    "Linear Regression:=Linear regression is used to estimate the dependent variable in case of a change in independent variables. For example, predict the price of houses.\n",
    "\n",
    "Logistic Regression:=Whereas logistic regression is used to calculate the probability of an event. For example, classify if tissue is benign or malignant.\n",
    "\n",
    "11.\n",
    "\n",
    "Linear Regression:=Linear regression assumes the normal or gaussian distribution of the dependent variable.\n",
    "\n",
    "Logistic Regression:=Logistic regression assumes the binomial distribution of the dependent variable.\n",
    "\n",
    "12.\t\n",
    "\n",
    "Linear Regression:=Applications of linear regression:=Financial risk assessment/Business insights/Market analysis/Applications of logistic \n",
    " \n",
    "regression:=Medicine/Credit scoring/Hotel Booking/Gaming/Text editing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d69fd-e2dc-4d2a-a4de-84ebcf26899b",
   "metadata": {},
   "source": [
    "## Q2. What is the cost function used in logistic regression, and how is it optimized?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7dd67f-6216-4c5e-af6f-a61345bdf530",
   "metadata": {},
   "source": [
    "The Cost Function measures the performance of a model by quantifying the error between predicted values and expected values. The bigger your loss is, the more different your predictions (ŷ) are from the true values (y). the cost of a function should be minimized, therefore, the model strives to attain the minimum on the graph. The minimum represents the optimal weights and (b) value that the independent variables (x) should use.\n",
    "\n",
    "For logistic regression, the C o s t function is defined as: C o s t (h θ (x), y) = { − log (h θ (x)) if y = 1 − log (1 − h θ (x)) if y = 0 The i indexes have been removed for clarity. In words this is the cost the algorithm pays if it predicts a value h θ (x) while the actual cost label turns out to be y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0979768e-aa05-4320-a2a7-4a575602f9b7",
   "metadata": {},
   "source": [
    "## Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f77ee-3c17-418d-9f9a-eafa3d439c12",
   "metadata": {},
   "source": [
    "Regularization is a method of preventing overfitting, which is a common problem in machine learning. Overfitting means that your model learns too much from the specific data you have, and fails to generalize well to new or unseen data. This can lead to poor predictions and low performance. Regularization helps you avoid overfitting by adding a penalty term to the cost function of your model, which measures how well your model fits the data. The penalty term reduces the complexity of your model by shrinking or eliminating some of the coefficients of your input variables.\n",
    "\n",
    "Logistic regression models are based on a mathematical function called the logistic function, which maps any input value to a number between 0 and 1. The coefficients of the input variables determine how much each variable affects the output of the logistic function. However, some of the coefficients may be too large or too small, which can cause overfitting or underfitting. Overfitting means that your model is too sensitive to some variables and ignores others, while underfitting means that your model is too simple and misses important patterns in the data. Regularization helps you balance the trade-off between overfitting and underfitting by adjusting the coefficients to optimal values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9bcf28-ae02-4387-be8e-ce0a26a1914b",
   "metadata": {},
   "source": [
    "## Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ecb2c-1f8c-4434-93c3-80cb4f0673af",
   "metadata": {},
   "source": [
    "Logistic Regression is a statistical method that we use to fit a regression model when the response variable is binary. To assess how well a logistic regression model fits a dataset, we can look at the following two metrics:\n",
    "\n",
    "Sensitivity: The probability that the model predicts a positive outcome for an observation when the outcome is indeed positive.\n",
    "\n",
    "Specificity: The probability that the model predicts a negative outcome for an observation when the outcome is indeed negative.\n",
    "An easy way to visualize these two metrics is by creating a ROC curve,\n",
    "\n",
    "When we create a ROC curve, we plot pairs of the true positive rate vs. the false positive rate for every possible decision threshold of a logistic regression model.\n",
    "\n",
    "How to Interpret a ROC Curve\n",
    "The more that the ROC curve hugs the top left corner of the plot, the better the model does at classifying the data into categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0370b6-00df-4ab1-9439-acc48dd30fb3",
   "metadata": {},
   "source": [
    "## Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e389448a-9a3c-45e2-9e37-58b120c671a6",
   "metadata": {},
   "source": [
    "There are several techniques that can be used to select the best features for a logistic regression model.\n",
    "\n",
    "1.Recursive Feature Elimination (RFE) is a feature selection technique that involves training a model on a subset of the features, and then iteratively removing the least important features one by one until we are left with the desired number of features.\n",
    "\n",
    "2.Wrapper approach to feature selection involves using a search algorithm to find the best combination of features for a predictive model. The goal is to find the combination of features that results in the best model performance, as measured by a metric such as accuracy or F1 score.\n",
    "\n",
    "3.Filter approach to feature selection involves using statistical tests or heuristics to select the most relevant features for a predictive model. The goal is to select features that are highly correlated with the target variable, as these are likely to be the most useful for prediction.\n",
    "\n",
    "4.Regardless of the method used, it is important to carefully evaluate the performance of the model on a validation set to ensure that the selected features are truly the most relevant and that the model is not overfitting to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9a8f1-a234-4bf5-b62d-b745f2c60d8e",
   "metadata": {},
   "source": [
    "## Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ea036-6dee-4c55-8512-341fc8966993",
   "metadata": {},
   "source": [
    "Logistic Regression is one of the supervised machine learning techniques that are used for classification tasks. Classification datasets most of the time will have a class imbalance with a certain class with more samples and certain classes with a very less number of samples. Using an imbalanced dataset for the model building would account for the wrong prediction and would be more favorable to classes with more samples.\n",
    "\n",
    "Class weights are terminology used for classification tasks where each category of the dataset will be provided with certain weights according to the frequency of occurrence of each category. So class weights will be responsible for giving equal weights for all categories on gradient updates. The usage of unbalanced class weights will be responsible for bias towards the most occurring categories in the data. To obtain a more reliable and unbiased classification model it is important to have a uniform distribution of class weights. Uniform distribution of class weights will also yield various parameters like precision, recall, and F1 score as the class weights would be balanced.\n",
    "\n",
    "The class weights can be balanced using the logistic regression model by just declaring the class_weight parameter as balanced in the logistic regression model. The class weights can be balanced automatically bypassing the standard parameter as balanced in class weights or random weights to each of the classes can be provided to each of the categories in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a4b80-b4b9-46a0-9cb1-d3a26e1f3f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
